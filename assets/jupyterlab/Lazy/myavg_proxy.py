
# generated by cpd_software_env

def gen_my_averages_a_b_proxy(cpd_url = None, space_name=None, space_id = None, deployment_name = None, token=None, vault=None,logdir="tmpjoboutput") : 
    """
    * cpd_url : url of CP4D server, default is os.environ["RUNTIME_ENV_APSX_URL"]
                note, this is not the scoring url of the specific deployment
    * space_name : name of deployment space
    * deployment_name : name of the deployment
    * token : CP4D bearer token, default is os.environ["USER_ACCESS_TOKEN"]
    * todo: vault_function : function that return a dict { "userid": id , "password": pw}
    """
    import os
    from datetime import datetime
    import cpd_software_env
    # todo, scoring_url parameter
    cpd_info = {}
    if cpd_url:
        cpd_info["url"] = cpd_url
    elif os.getenv("RUNTIME_ENV_APSX_URL") :
        cpd_info["url"] = os.environ["RUNTIME_ENV_APSX_URL"]
    if token :
        cpd_info["token"] = token
    elif os.getenv("USER_ACCESS_TOKEN") :
        cpd_info["token"] = os.environ["USER_ACCESS_TOKEN"]
    if space_id:
        cpd_info["space_id"] = space_id
        os.environ["SPACE_ID"] = space_id
    elif space_name:
        cpd_info["space_id"] = cpd_software_env._lookup_cpd_space_id(cpd_info["url"], cpd_info["token"], space_name)
        os.environ["SPACE_ID"] = cpd_info["space_id"] # used below when calling the score fn
        
    assert deployment_name
    # cpd_software_env.cpd_lookup_asset(cpd_info,"deployment",name=deployment_name)
    # ... doesn't work, deployments are not assets
    res = cpd_software_env._cpd_rest_request35(cpd_info,"GET",f"/ml/v4/deployments?name={deployment_name}")
    assert res.json()["resources"], f"deployment '{deployment_name}' not found"
    deployment = res.json()["resources"][0]
    deployment_id = deployment["metadata"]["id"]
    #print("deployment = ",deployment_id,deployment)  # debug
    # 'deployed_asset_type': 'py_script'
    # 'deployed_asset_type': 'function',
    if deployment["entity"].get('deployed_asset_type') == 'py_script':
        if not False:
            msg = "Proxy code was generated for a deployed function. But the actual deployment runs a script. Re-generate the code using gencode_scoring_proxy(..,use_data_refs=True)"
            raise ValueError("Mismatch between type of input data and deployed asset",msg)
    if deployment["entity"].get('deployed_asset_type') == 'function':
        if  False:    
            print("Mismatch in input_data vs data refs")
            msg = "Proxy code was generated for a deployed script. But the actual deployment runs a function. Re-generate the code using gencode_scoring_proxy(..,use_data_refs=False)"
            raise ValueError("Mismatch between type of input data and deployed asset",msg)  
            
    if "batch" in deployment["entity"] :
        online_or_batch = "batch"
        if os.getenv('CPD_SOFTWARE_ENV_VERBOSE') : 
            print(datetime.now().strftime('%H:%M:%S'),"Found Batch Job")
        # deployed asset can be script or wml_function
        # todo:
        # script requires use_data_refs=True
        # wml_function requires use_data_refs=False
    else:
        assert "online" in deployment["entity"], "deployment must be either batch or online"
        online_or_batch = "online"
        scoring_url = deployment["entity"]["status"]["online_url"]["url"]
        if os.getenv('CPD_SOFTWARE_ENV_VERBOSE') : 
            print(datetime.now().strftime('%H:%M:%S'),"Found online endpoint",scoring_url)
            
    def _lookup_deployed_asset_href():
        nonlocal deployment
        asset_id = deployment['entity']['asset']['id']
        space_id = deployment['entity']['space_id']
        #tmpasset=cpd_software_env.cpd_lookup_asset(cpd_info,"script",id=asset_id)
        #print("tmpasset href=",tmpasset['href'])
        #print("my href=   ",f"/v2/assets/{asset_id}?space_id={space_id}")
        return f"/v2/assets/{asset_id}?space_id={space_id}"
            
    def submit_online_request(wml_data_submit):
        nonlocal scoring_url
        res = cpd_software_env._cpd_rest_request35(
                    {"url":scoring_url},"POST","",json=wml_data_submit)
        return res.json()
        
    wml_client = cpd_software_env._wml_connect_env()
    wml_client.set.default_space(cpd_info["space_id"])
    # todo: replace wml_client with rest call
    def submit_batch_request(wml_data_submit):
        import time,sys
        nonlocal deployment_id,cpd_info,wml_client,logdir
        jobrun = wml_client.deployments.create_job(
                deployment_id=deployment_id,
                meta_props=wml_data_submit)
        job_id = wml_client.deployments.get_job_uid(jobrun)
        print("Job run started:",wml_client.deployments.get_job_status(job_id)["state"])
        timeout_iterations = 200
        while True :
            status = wml_client.deployments.get_job_status(job_id)
            if status['state'] != 'queued' and status['state'] != 'running' :
                break
            if timeout_iterations <= 0 :
                print("giving up")
                break
            print(".",end="");sys.stdout.flush()
            time.sleep(5)
            timeout_iterations -= 1
        print("") # newline after ...
        details = wml_client.deployments.get_job_details(job_id)
        #print("scoring =",details['entity']['scoring'])
        print("state =",details['entity']['scoring']['status']['state'])
        from cpd_software_env import _job_download_output # todo: make inline
        _job_download_output(wml_client,job_id,job_details=details,local_dir=logdir)
        # Batch deployment of a Py Function returns predictions in job details
        # Batch deployment of a Py Function does not produce a file "result.json"
        # Batch deployment of a Py Script does not return predictions in job details
        # Batch deployment of a Py Script produces a file "result.json" or it has failed
        import os
        fname = os.path.join(logdir,"result.json")
        if details['entity']['scoring']['status']['state'] == "failed":
            # todo, check if any log file is available
            raise Exception("Batch job failed",details['entity']['scoring']['status'])
        elif not ( os.path.isfile(fname) or 'predictions' in details['entity']['scoring'] ) :
            # job failed
            job_error_msg = "Batch result missing : "
            job_error_msg += str(details['entity']['scoring']['status'].get('message','no message'))
            # e.g. message={'text': 'output_data_reference is not provided in the payload'}
            # happens when batch script is called with inline input_data
            raise Exception(job_error_msg)
        #
        assert os.path.isfile(fname) or 'predictions' in details['entity']['scoring'], "Result missing"
        if 'predictions' in details['entity']['scoring'] :
            assert not os.path.isfile(fname) 
        if os.path.isfile(fname) :
            assert 'predictions' not in details['entity']['scoring']  
        if 'predictions' not in details['entity']['scoring'] :
            try:
                import json,os
                #print("result file? ",os.path.join(logdir,"result.json"))
                fp = open(os.path.join(logdir,"result.json"))
                #print("found",os.path.join(logdir,"result.json"))
                try:
                    score_res = json.load(fp)
                    fp.close()
                except Exception as exc:
                    print("Error loading JSON")
                    score_res = str(exc)
                # cf gencode_deployable_function  template_post
                # WML expects { 'predictions': [some_dictionary] }
                if isinstance(score_res,dict):
                    result = score_res
                else:
                    result = {}
                    #result['autoinstall msgs'] = cpd_software_env.get_msgs()   
                    result['score'] =  score_res
            except Exception as exc:
                print("Warning: no result.json found")
                result = str(exc)
            if os.getenv('CPD_SOFTWARE_ENV_VERBOSE') : 
                print(datetime.now().strftime('%H:%M:%S'),'batch result',result)
            details['entity']['scoring']['predictions'] = [result]
        #
        #print("predictions",details['entity']['scoring']['predictions'])
        if details['entity']['scoring']['status']['state'] == "failed":
            raise Exception("submit_batch_request",details['entity']['scoring']['status'])
        return details['entity']['scoring']
        # returns a dictionary with key 'predictions', consistent with result from online scoring
  
    import pandas
    def my_averages_a_b_proxy(indata: pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame:
        nonlocal online_or_batch
        import os
        envvars={}
        if os.getenv('USER_ACCESS_TOKEN'): envvars['USER_ACCESS_TOKEN']=os.environ['USER_ACCESS_TOKEN']
        if os.getenv('SPACE_ID'): envvars['SPACE_ID']=os.environ['SPACE_ID']
        d1 = { 'fields':list(indata.columns), 'values':indata.values.tolist() }
        d1['name'] = 'indata'
        d1['environment_variables'] = envvars
        data_list = [d1]
        data_list[0]['tail'] = data_list[1:]
        wml_data = { 'input_data': data_list}
        if os.getenv('CPD_SOFTWARE_ENV_VERBOSE') : print(datetime.now().strftime('%H:%M:%S'),'wml_data',wml_data)
        if online_or_batch == 'online' :
            wml_result = submit_online_request(wml_data)
        else :
            wml_result = submit_batch_request(wml_data)
        if os.getenv('CPD_SOFTWARE_ENV_VERBOSE') : print(datetime.now().strftime('%H:%M:%S'),'wml_result',wml_result)
        # todo: make sure that batch logs get downloaded before any other error/exception exits the app
        if not isinstance(wml_result,dict): return wml_result
        if 'predictions' not in wml_result: return wml_result
        import pandas as pd
        d = wml_result["predictions"][0]
        return pd.DataFrame(d["values"],columns=d.get("fields",[]))

    return my_averages_a_b_proxy